# 🧭 Scaffolding, Reflection, and Open Discussion with GitHub Copilot

This guide helps faculty integrate GitHub Copilot into their courses in a thoughtful, structured, and inclusive way. Use these strategies to ensure Copilot becomes a learning partner—not a shortcut.

---

## 🧱 Scaffolding GitHub Copilot Use

**🎯 Goal:** Guide students in learning how to use Copilot critically—not just that it exists.

### Why It Matters

Without structure, students may:
- Over-rely on AI-generated code
- Skip foundational problem-solving steps
- Miss opportunities to build independent confidence

Scaffolding supports gradual, intentional use and encourages **judgment over automation**.

### 🔧 Strategies

#### ✅ Start with Guided Prompts

Begin with clear prompts, such as:

// Create a function to calculate total cost with tax

Ask students to:
- Observe Copilot’s suggestion
- Compare it to how they’d solve it themselves
- Edit the result to follow class conventions or style guides

*Example: Show students multiple Copilot suggestions and have them rate each one’s clarity, efficiency, and accuracy.*

#### 📈 Use Progressive Complexity

Start in low-stakes environments:
- Convert pseudocode → Copilot suggestion → manual rewrite
- Scaffold short tasks before full projects

Later stages:
- Require revision logs
- Annotate code where Copilot was used
- Justify decisions during project checkpoints

#### 🧑‍🤝‍🧑 Assign Roles in AI Pair Programming

Use peer roles:
- One student types with Copilot
- One critiques suggestions and records decisions
- Then switch roles.

*Bonus: Create a shared log: “Copilot suggested X, we chose Y because...”*

#### 🚦 Build “Copilot Checkpoints” into Assignments

Prompt students to include comments like:

// Copilot suggested this loop structure. I modified it to include input validation.

- Encourage at least 2–3 “checkpoint comments” per project or lab.

## 🪞 Reflection

**🎯 Goal:** Encourage metacognition—help students think about their thinking and coding decisions.
Why It Matters

### Reflection:
- Surfaces comprehension beyond a working product
- Strengthens critical thinking and self-awareness
- Provides instructors with insight into student decision-making

#### 🧠 Reflection Prompts

Use in journals, discussion boards, or post-lab reports:
- What did Copilot suggest, and did you accept or reject it? Why?
- How did Copilot influence your problem-solving approach?
- What did you learn by editing Copilot’s code?
- How would your code differ without Copilot?
- Would you trust this code in a real-world application?
- What surprised you about Copilot’s suggestions?
- How did you verify that Copilot’s code worked?
- Did Copilot ever suggest something incorrect? How did you handle it?
- Would you recommend using Copilot to another student? Why or why not?
- What’s one thing you understand better now after using Copilot?

#### 💡 Implementation Ideas

Add prompts to:
- Exit tickets
- Journals
- Quizzes

Pair with:
- Peer reviews
- Commit history reviews

*Example: "Review your partner’s Copilot comment logs. What patterns do you see in their decisions?"*

## 🗣️ Open Discussion

**🎯 Goal:** Normalize classroom conversation about AI’s role in learning and the workplace.
Why It Matters

### Students (and faculty!) benefit from critical reflection on:
- The ethics of automation
- Ownership of work
- AI literacy and career preparation

#### 💬 Discussion Starters
- When does Copilot help you learn, and when does it hold you back?
- Should there be limits on AI use in class? Why or why not?
- How might an employer view your use of Copilot?
- What responsibilities do you have when submitting AI-assisted code?
- How is using Copilot different from using Stack Overflow?
- What values should guide our use of AI in education?
- If Copilot makes a mistake, who is responsible?
- Should we cite AI tools like Copilot in our code? Why or why not?
- Does Copilot create an unfair advantage for some students?
- What would a “responsible use” policy for Copilot look like?

#### ✅ Best Practices for Facilitating Discussion
- Bring real examples (e.g., flawed Copilot output)
- Acknowledge known issues (bias, hallucination, inefficiency)
- Connect to academic honesty:
    *“Just like citing a source, let’s talk about citing our AI collaborators.”*

📌 Created by Jennifer Lee to support reflective, ethical, and student-centered use of AI in the coding classroom.
