# ğŸ§­ Scaffolding, Reflection, and Open Discussion with GitHub Copilot

This guide helps faculty integrate GitHub Copilot into their courses in a thoughtful, structured, and inclusive way. Use these strategies to ensure Copilot becomes a learning partnerâ€”not a shortcut.

---

## ğŸ§± Scaffolding GitHub Copilot Use

**ğŸ¯ Goal:** Guide students in learning how to use Copilot criticallyâ€”not just that it exists.

### Why It Matters

Without structure, students may:
- Over-rely on AI-generated code
- Skip foundational problem-solving steps
- Miss opportunities to build independent confidence

Scaffolding supports gradual, intentional use and encourages **judgment over automation**.

### ğŸ”§ Strategies

#### âœ… Start with Guided Prompts

Begin with clear prompts, such as:

// Create a function to calculate total cost with tax

Ask students to:
- Observe Copilotâ€™s suggestion
- Compare it to how theyâ€™d solve it themselves
- Edit the result to follow class conventions or style guides

*Example: Show students multiple Copilot suggestions and have them rate each oneâ€™s clarity, efficiency, and accuracy.*

#### ğŸ“ˆ Use Progressive Complexity

Start in low-stakes environments:
- Convert pseudocode â†’ Copilot suggestion â†’ manual rewrite
- Scaffold short tasks before full projects

Later stages:
- Require revision logs
- Annotate code where Copilot was used
- Justify decisions during project checkpoints

#### ğŸ§‘â€ğŸ¤â€ğŸ§‘ Assign Roles in AI Pair Programming

Use peer roles:
- One student types with Copilot
- One critiques suggestions and records decisions
- Then switch roles.

*Bonus: Create a shared log: â€œCopilot suggested X, we chose Y because...â€*

#### ğŸš¦ Build â€œCopilot Checkpointsâ€ into Assignments

Prompt students to include comments like:

// Copilot suggested this loop structure. I modified it to include input validation.

- Encourage at least 2â€“3 â€œcheckpoint commentsâ€ per project or lab.

## ğŸª Reflection

**ğŸ¯ Goal:** Encourage metacognitionâ€”help students think about their thinking and coding decisions.
Why It Matters

### Reflection:
- Surfaces comprehension beyond a working product
- Strengthens critical thinking and self-awareness
- Provides instructors with insight into student decision-making

#### ğŸ§  Reflection Prompts

Use in journals, discussion boards, or post-lab reports:
- What did Copilot suggest, and did you accept or reject it? Why?
- How did Copilot influence your problem-solving approach?
- What did you learn by editing Copilotâ€™s code?
- How would your code differ without Copilot?
- Would you trust this code in a real-world application?
- What surprised you about Copilotâ€™s suggestions?
- How did you verify that Copilotâ€™s code worked?
- Did Copilot ever suggest something incorrect? How did you handle it?
- Would you recommend using Copilot to another student? Why or why not?
- Whatâ€™s one thing you understand better now after using Copilot?

#### ğŸ’¡ Implementation Ideas

Add prompts to:
- Exit tickets
- Journals
- Quizzes

Pair with:
- Peer reviews
- Commit history reviews

*Example: "Review your partnerâ€™s Copilot comment logs. What patterns do you see in their decisions?"*

## ğŸ—£ï¸ Open Discussion

**ğŸ¯ Goal:** Normalize classroom conversation about AIâ€™s role in learning and the workplace.
Why It Matters

### Students (and faculty!) benefit from critical reflection on:
- The ethics of automation
- Ownership of work
- AI literacy and career preparation

#### ğŸ’¬ Discussion Starters
- When does Copilot help you learn, and when does it hold you back?
- Should there be limits on AI use in class? Why or why not?
- How might an employer view your use of Copilot?
- What responsibilities do you have when submitting AI-assisted code?
- How is using Copilot different from using Stack Overflow?
- What values should guide our use of AI in education?
- If Copilot makes a mistake, who is responsible?
- Should we cite AI tools like Copilot in our code? Why or why not?
- Does Copilot create an unfair advantage for some students?
- What would a â€œresponsible useâ€ policy for Copilot look like?

#### âœ… Best Practices for Facilitating Discussion
- Bring real examples (e.g., flawed Copilot output)
- Acknowledge known issues (bias, hallucination, inefficiency)
- Connect to academic honesty:
    *â€œJust like citing a source, letâ€™s talk about citing our AI collaborators.â€*

ğŸ“Œ Created by Jennifer Lee to support reflective, ethical, and student-centered use of AI in the coding classroom.
